{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from retrying import retry\n",
    "from retrying import RetryError\n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "\n",
    "DEVELOPER_KEY=[]\n",
    "for x in range(2,8):\n",
    "    if (x==2):\n",
    "        DEVELOPER_KEY.append(os.environ.get('API_CODE'))\n",
    "        DEVELOPER_KEY.append(os.environ.get('API_CODE2'))\n",
    "    else:\n",
    "        DEVELOPER_KEY.append(os.environ.get('API_CODE'+str(x)))\n",
    "                             \n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "service= build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_503_error(exception):\n",
    "    is503=False\n",
    "    if (isinstance(exception, HttpError)):\n",
    "        if (exception.resp.status==503):\n",
    "            is503=True\n",
    "    return (is503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop_max_attempt_number=7,retry_on_exception=is_503_error, \n",
    "       wrap_exception=True,wait_random_min=1000, wait_random_max=2000)\n",
    "\n",
    "def comment_thread_list(pageToken, videoId):\n",
    "\n",
    "    commentList=service.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=videoId,\n",
    "        maxResults=100,\n",
    "        order='relevance',\n",
    "        pageToken=pageToken\n",
    "    ).execute()\n",
    "    \n",
    "    return commentList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_by_video(videoId,videoYear,writer,ferror):\n",
    "    this_quota=0\n",
    "    pageToken=\"\"\n",
    "    c=0\n",
    "    \n",
    "    #gets information until there is no next page\n",
    "    while (pageToken!='error') and (c<=50):\n",
    "        \n",
    "        try:\n",
    "            commentList=comment_thread_list(pageToken,videoId)\n",
    "            this_quota+=20\n",
    "            # track quota inside function\n",
    "#             print(this_quota)\n",
    "        except RetryError as e:\n",
    "#             print(e)\n",
    "            with open(ferror, 'a') as f:\n",
    "                f.write(\"max unsuccessful attempts reached\"+\" videoId:\"+videoId+'\\n')\n",
    "                this_quota+=30\n",
    "                # track quota inside function\n",
    "#                 print('error:'+str(this_quota))\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        #save list of videos if the list is not empty\n",
    "        if (commentList.get(\"items\",[])!=[]):\n",
    "            \n",
    "            for item in commentList.get(\"items\",[]):\n",
    "                year=2019\n",
    "                dictio={}\n",
    "                dictio['videoId']= videoId\n",
    "                dictio['year']=videoYear\n",
    "                \n",
    "                if 'id' in item['snippet']['topLevelComment']:\n",
    "                    dictio['commentId']=item['snippet']['topLevelComment']['id']\n",
    "                    \n",
    "                if 'authorDisplayName' in item['snippet']['topLevelComment']['snippet']:\n",
    "                    dictio['authorName']=item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "                \n",
    "                if 'authorChannelId' in item['snippet']['topLevelComment']['snippet']:\n",
    "                    dictio['authorChannelId']=item['snippet']['topLevelComment']['snippet']['authorChannelId']['value']\n",
    "                \n",
    "                if 'textDisplay' in item['snippet']['topLevelComment']['snippet']:\n",
    "                    dictio['textDisplay']=item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                \n",
    "                if 'textOriginal' in item['snippet']['topLevelComment']['snippet']:\n",
    "                    dictio['textOriginal']=item['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "                    \n",
    "                if 'likeCount' in item['snippet']['topLevelComment']['snippet']:\n",
    "                    dictio['likeCount']=item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "                    \n",
    "                if 'publishedAt' in item['snippet']['topLevelComment']['snippet']:\n",
    "                    pubAt=item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "                    date=datetime.strptime(pubAt, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                    year =date.year\n",
    "                    dictio['pYear']= date.year\n",
    "                    dictio['pMonth']=date.month\n",
    "                    dictio['pDay']= date.day\n",
    "                \n",
    "                if (year<=2016):\n",
    "                    writer.writerow(dictio)\n",
    "                    c+=1\n",
    "\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "        try:\n",
    "            pageToken=commentList['nextPageToken']\n",
    "        except KeyError as e:\n",
    "            pageToken='error'\n",
    "        \n",
    "        if this_quota>=180000:\n",
    "            break\n",
    "            \n",
    "    return this_quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruiz/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/aruiz/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "community_num=[9,22,85,76,71,37,87]\n",
    "data_islp='/media/aruiz/data/videos_data/islp/'\n",
    "data_comments='/media/aruiz/data/comments_data/'\n",
    "fieldnames=['videoId','year','commentId','authorName','authorChannelId','textDisplay','textOriginal','likeCount',\n",
    "            'pYear', 'pMonth','pDay']\n",
    "fError=os.path.join(data_comments,'errors.txt')\n",
    "quota=250000\n",
    "key=0\n",
    "\n",
    "for ind in range (0, 1):\n",
    "# for ind in range (2, len(community_num)):\n",
    "    f=os.path.join(data_islp,'data_community_'+str(community_num[ind])+'_islp.csv')\n",
    "    fileName1=os.path.join(data_comments,'community'+str(community_num[ind])+'_allPositive.csv')\n",
    "    out1=open(fileName1, 'a')\n",
    "    writer1 = csv.DictWriter(out1, fieldnames=fieldnames)\n",
    "    writer1.writeheader()\n",
    "    fileName2=os.path.join(data_comments,'community'+str(community_num[ind])+'_allNegative.csv')\n",
    "    out2=open(fileName2, 'a')\n",
    "    writer2 = csv.DictWriter(out2, fieldnames=fieldnames)\n",
    "    writer2.writeheader()\n",
    "    \n",
    "    df=pd.read_csv(f)\n",
    "    df=df.fillna(0.0)\n",
    "    df=df[df['is_letPlay']==True]\n",
    "    df=df[df['categoryId']==20]      \n",
    "\n",
    "    for dyear in range (2008,2017):\n",
    "#     for dyear in range (2014,2017):\n",
    "        dft=df[df['year']==dyear]\n",
    "        \n",
    "        # get the first 100 videos ids\n",
    "        if len(dft)>100:\n",
    "            if dyear>=2010:\n",
    "                # Values to get rating of most liked/disliked videos\n",
    "                dft['ratio']= dft['likeCount']-dft['dislikeCount']\n",
    "                dft=dft.sort_values(by=['ratio'],ascending=False)\n",
    "                dft=dft.reset_index(drop=True)\n",
    "            \n",
    "            #get top 100 of most approved videos\n",
    "            ids=dft.id[0:100]\n",
    "        else:\n",
    "            if dyear>=2010:\n",
    "                # Values to get rating of most liked/disliked videos\n",
    "                dft['ratio']= dft['likeCount']-dft['dislikeCount']\n",
    "                dft=dft.sort_values(by=['ratio'],ascending=False)\n",
    "                dft=dft.reset_index(drop=True)\n",
    "                \n",
    "            ids=dft.id\n",
    "\n",
    "        #writing all approved videos comments\n",
    "        for i in ids:\n",
    "            this_quota=comments_by_video(i,dyear,writer1,fError)\n",
    "            quota+=this_quota\n",
    "#             print (quota)\n",
    "\n",
    "            if (quota>=800000):\n",
    "                quota=0\n",
    "                key+=1\n",
    "                if (key==7):\n",
    "                    key=0                        \n",
    "                service= build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY[key])\n",
    "                continue\n",
    "\n",
    "        if dyear>=2010:   \n",
    "            dft=dft[dft['ratio']<0]\n",
    "            ids=dft.id            \n",
    "        \n",
    "            #writing all disapproved videos comments\n",
    "            for i in ids:\n",
    "                this_quota=comments_by_video(i,dyear,writer2,fError)\n",
    "                quota+=this_quota\n",
    "\n",
    "                if (quota>=800000):\n",
    "                    quota=0\n",
    "                    key+=1\n",
    "                    if (key==7):\n",
    "                        key=0                        \n",
    "                    service= build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY[key])\n",
    "                    continue\n",
    "                    \n",
    "    out1.close()\n",
    "    out2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear all files to start again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruiz/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community9\n",
      "\n",
      "2008 354\n",
      "2009 1468\n",
      "2010 4006\n",
      "negative: 5\n",
      "2011 7362\n",
      "negative: 17\n",
      "2012 16389\n",
      "negative: 51\n",
      "2013 19349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruiz/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative: 40\n",
      "2014 26544\n",
      "negative: 50\n",
      "2015 21995\n",
      "negative: 147\n",
      "2016 26343\n",
      "negative: 72\n",
      "community22\n",
      "\n",
      "2008 11\n",
      "2009 54\n",
      "2010 685\n",
      "negative: 10\n",
      "2011 2986\n",
      "negative: 19\n",
      "2012 6104\n",
      "negative: 16\n",
      "2013 8580\n",
      "negative: 44\n",
      "2014 11219\n",
      "negative: 34\n",
      "2015 10600\n",
      "negative: 139\n",
      "2016 10949\n",
      "negative: 36\n",
      "community85\n",
      "\n",
      "2008 3\n",
      "2009 34\n",
      "2010 70\n",
      "negative: 2\n",
      "2011 976\n",
      "negative: 10\n",
      "2012 2059\n",
      "negative: 16\n",
      "2013 2446\n",
      "negative: 21\n",
      "2014 2488\n",
      "negative: 9\n",
      "2015 2220\n",
      "negative: 8\n",
      "2016 1955\n",
      "negative: 3\n",
      "community76\n",
      "\n",
      "2008 0\n",
      "2009 0\n",
      "2010 0\n",
      "negative: 0\n",
      "2011 21\n",
      "negative: 0\n",
      "2012 87\n",
      "negative: 0\n",
      "2013 90\n",
      "negative: 1\n",
      "2014 138\n",
      "negative: 1\n",
      "2015 454\n",
      "negative: 2\n",
      "2016 580\n",
      "negative: 3\n",
      "community71\n",
      "\n",
      "2008 1\n",
      "2009 1\n",
      "2010 34\n",
      "negative: 0\n",
      "2011 170\n",
      "negative: 0\n",
      "2012 310\n",
      "negative: 2\n",
      "2013 880\n",
      "negative: 6\n",
      "2014 1065\n",
      "negative: 15\n",
      "2015 962\n",
      "negative: 10\n",
      "2016 899\n",
      "negative: 25\n",
      "community37\n",
      "\n",
      "2008 0\n",
      "2009 0\n",
      "2010 0\n",
      "negative: 0\n",
      "2011 35\n",
      "negative: 0\n",
      "2012 199\n",
      "negative: 1\n",
      "2013 254\n",
      "negative: 1\n",
      "2014 160\n",
      "negative: 0\n",
      "2015 272\n",
      "negative: 0\n",
      "2016 527\n",
      "negative: 1\n",
      "community87\n",
      "\n",
      "2008 0\n",
      "2009 0\n",
      "2010 1\n",
      "negative: 0\n",
      "2011 129\n",
      "negative: 0\n",
      "2012 441\n",
      "negative: 2\n",
      "2013 1262\n",
      "negative: 2\n",
      "2014 1770\n",
      "negative: 0\n",
      "2015 1040\n",
      "negative: 0\n",
      "2016 1574\n",
      "negative: 3\n"
     ]
    }
   ],
   "source": [
    "community_num=[9,22,85,76,71,37,87]\n",
    "data_islp='/media/aruiz/data/videos_data/islp/'\n",
    "data_comments='/media/aruiz/data/comments_data/'\n",
    "fieldnames=['videoId','year','commentId','authorName','authorChannelId','textDisplay','textOriginal','likeCount',\n",
    "            'publishedAt']\n",
    "fError=os.path.join(data_comments,'errors.txt')\n",
    "quota=0\n",
    "\n",
    "for ind in range (0, len(community_num)):\n",
    "    f=os.path.join(data_islp,'data_community_'+str(community_num[ind])+'_islp.csv')\n",
    "#     fileName1=os.path.join(data_comments,'community'+str(community_num[ind])+'_allPositive.csv')\n",
    "#     out1=open(fileName1, 'a')\n",
    "#     writer1 = csv.DictWriter(out1, fieldnames=fieldnames)\n",
    "#     writer1.writeheader()\n",
    "#     fileName2=os.path.join(data_comments,'community'+str(community_num[ind])+'_allNegative.csv')\n",
    "#     out2=open(fileName2, 'a')\n",
    "#     writer2 = csv.DictWriter(out2, fieldnames=fieldnames)\n",
    "#     writer2.writeheader()\n",
    "    \n",
    "#     this_quota=comments_by_video('098F0WJTRK4',2014,writer2,fError)\n",
    "#     break\n",
    "    df=pd.read_csv(f)\n",
    "    df=df.fillna(0.0)\n",
    "    df=df[df['is_letPlay']==True]\n",
    "    df=df[df['categoryId']==20]      \n",
    "    print (\"community\"+str(community_num[ind])+'\\n')\n",
    "\n",
    "    for dyear in range (2008,2017):\n",
    "        dft=df[df['year']==dyear]\n",
    "        print (str(dyear)+ \" \"+ str(len(dft)))\n",
    "        \n",
    "        if dyear>=2010:\n",
    "            # Values to get rating of most liked/disliked videos\n",
    "            dft['ratio']= dft['likeCount']-dft['dislikeCount']\n",
    "            dft=dft.sort_values(by=['ratio'],ascending=False)\n",
    "            dft=dft.reset_index(drop=True)\n",
    "            dft=dft[dft['ratio']<0]\n",
    "            print(\"negative: \"+str(len(dft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method():\n",
    "    i=0\n",
    "    pageToken=\"\"\n",
    "    c=0\n",
    "\n",
    "    while pageToken!='error' and c<=10:\n",
    "            i+=1\n",
    "            if i>=51:\n",
    "                break\n",
    "            if i==50:\n",
    "                c+=1\n",
    "                pageToken='error'\n",
    "            \n",
    "    return c,pageToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,pg=method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'error'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
