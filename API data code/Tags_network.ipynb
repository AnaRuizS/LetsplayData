{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channels' tags network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import math\n",
    "import json\n",
    "import shlex\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "\n",
    "from pandas import Series\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruiz/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "data_folder_channels='/media/aruiz/data/channels_clean_data/'\n",
    "fileName2=os.path.join(data_folder_channels,'all_channels_cat_clean.csv')\n",
    "# fileName2=os.path.join(data_folder_channels,'gta_data_clean.csv')\n",
    "df=pd.read_csv(fileName2)\n",
    "df=df.sort_values(by=['views'],ascending=True)\n",
    "df=df.fillna(\"N/A\")\n",
    "df=df.reset_index(drop=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopWords = set(stopwords.words('english'))\n",
    "searchKeys=[\"minecraft\",\"roblox\",\"call\", \"of\", \"duty\",\"overwatch\", \"grand\",\"theft\",\"auto\",\"league\",\"legend\",\n",
    "            \"Happy\",\"wheel\",\"five\", \"night\", \"at\", \"freddy's\",\"agar.io\", \"pokemon\"]\n",
    "# searchKeys=[\"grand\",\"theft\",\"auto\"]\n",
    "top_words= [\"game\", \"gaming\", \"video\", \"gameplay\", \"funny\", \"play\", \"let\",\"cod\", \"mod\", \"tutorial\"]\n",
    "# quartile3=246352\n",
    "quartile3=42267\n",
    "#punctuation list to exclude from keywords\n",
    "exclude = set(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write keywords per channel in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to delete numbers and punctuation signs\n",
    "def remove_dig_punct(list1):\n",
    "    new=[]\n",
    "    for n in range (0, len(list1)):\n",
    "        #removing digits\n",
    "        res=''.join([i for i in list1[n] if not i.isdigit()])\n",
    "        #removing punctuation\n",
    "        s = ''.join(ch for ch in res if ch not in exclude)\n",
    "        if (s !=\"\") and (s not in new):\n",
    "            if (len(s)>1):\n",
    "                new.append(s)\n",
    "    return (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"channel_id_tags.json\", 'w') as f:\n",
    "    for n in range(0,len(df)):\n",
    "        if (df.keywords[n]!=\"N/A\") and (df.views[n]>quartile3):\n",
    "            d1={}\n",
    "            channel_keys=[]\n",
    "\n",
    "            try:\n",
    "                l = shlex.split(df.keywords[n])\n",
    "\n",
    "            except:\n",
    "                l = df.keywords[n].split()\n",
    "\n",
    "            for kw in l:\n",
    "                kw_id = kw.lower().replace(\"'\", \"\").replace(\"´\", \"\").replace(\"’\", \"\").replace(\"`\", \"\")\n",
    "                single_keys=nltk.word_tokenize(kw_id)\n",
    "                for key in single_keys:\n",
    "                    key=lemmatizer.lemmatize(key)\n",
    "                    if (key not in stopWords)and(len(key)>1):\n",
    "                        if (key not in channel_keys) and (key not in searchKeys):\n",
    "                            channel_keys.append(key)\n",
    "\n",
    "    #         clean all digits and punctuation from keywords\n",
    "            channel_keys_clean=remove_dig_punct(channel_keys)\n",
    "\n",
    "    #         df.loc[n,\"num_tags\"]=len(channel_keys_clean)\n",
    "            for key in channel_keys_clean: d1[key]=True\n",
    "            d1[\"id\"]=df.id[n]\n",
    "#             dictionaries.append(d1)\n",
    "            f.write(json.dumps(d1))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct graph network with weighted edges (w = number of shared tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create nodes with weight and title\n",
    "G=nx.Graph()\n",
    "with open(\"channel_id_tags.json\", 'r') as f:\n",
    "    for line in f:\n",
    "        comp1=json.loads(line)\n",
    "        channel=df.loc[df[\"id\"]==comp1[\"id\"],[\"title\", \"views\", \"game_q\"]]\n",
    "        if len(str(channel.game_q.values[0]))==1:\n",
    "            cat=int(channel.game_q.values[0])\n",
    "        else:\n",
    "            cat=10\n",
    "        G.add_node(comp1[\"id\"], name=channel.title.values[0], weight=int(channel.views.values[0]),category=cat)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_line_dict(n, filename):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        comp1={}\n",
    "        for i,line in enumerate(f):\n",
    "            if i==n:\n",
    "                comp1=json.loads(line)\n",
    "                break\n",
    "    f.close()\n",
    "    return comp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range (0,22415):\n",
    "    comp1= return_line_dict(n,\"channel_id_tags.json\")\n",
    "    with open(\"channel_id_tags.json\", 'r') as f:\n",
    "        for j,line in enumerate(f):\n",
    "            if j>=n+1:\n",
    "                comp2=json.loads(line)\n",
    "                shared_items = set(comp1.items()) & set(comp2.items())\n",
    "                shared_len=len(shared_items)\n",
    "                if (shared_len>=7):\n",
    "                    G.add_edge(comp1[\"id\"],comp2[\"id\"], weight=int(shared_len), shared=shared_items)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nodes(new_node, node_list, gf):\n",
    "    H =gf.copy()\n",
    "    gf.add_node(new_node, type='keyword') # Add the 'merged' node   \n",
    "\n",
    "    for n1,n2,data in H.edges(data=True):\n",
    "        # For all edges related to one of the nodes to merge,\n",
    "        # make an edge going to or coming from the `new gene`.\n",
    "        if n1 in node_list:\n",
    "            g.add_edge(new_node,n2)\n",
    "        elif n2 in node_list:\n",
    "            g.add_edge(n1,new_node)\n",
    "\n",
    "    for n in node_list: # remove the merged nodes\n",
    "        gf.remove_node(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove isolates and keep strong edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=G.copy()\n",
    "a=list(nx.isolates(G))\n",
    "H.remove_nodes_from(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_sum=0\n",
    "for u,v,d in G.edges(data=True):\n",
    "    if d['weight']<=6:\n",
    "        H.remove_edge(u,v)\n",
    "#         cum_sum+=1\n",
    "#         print(u,\"\",v, d['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u,v,d in H.edges(data=True):\n",
    "    d['shared']=dict(d['shared'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952\n",
      "60048\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(H.nodes()))\n",
    "print(len(H.edges()))\n",
    "print(len(list(nx.isolates(H))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution=[]\n",
    "for u,v,d in H.edges(data=True):\n",
    "    distribution.append(d['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(H,\"similarity_tag_cat8_64_data.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=[]\n",
    "K=[]\n",
    "L=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_w=Series(distribution)\n",
    "rep=counts_w.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     32475\n",
       "8     14279\n",
       "9      6585\n",
       "10     3285\n",
       "11     1585\n",
       "12      767\n",
       "13      418\n",
       "14      232\n",
       "15      140\n",
       "16       85\n",
       "17       41\n",
       "18       38\n",
       "19       28\n",
       "20       18\n",
       "21       12\n",
       "25       12\n",
       "22        9\n",
       "27        8\n",
       "23        6\n",
       "26        3\n",
       "29        3\n",
       "35        2\n",
       "34        2\n",
       "33        2\n",
       "37        2\n",
       "32        2\n",
       "30        2\n",
       "24        2\n",
       "28        2\n",
       "40        1\n",
       "64        1\n",
       "31        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
