{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channels' tags network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import math\n",
    "import shlex\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from string import punctuation\n",
    "\n",
    "from pandas import Series\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruiz/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "data_folder_channels='/media/aruiz/data/channels_clean_data/'\n",
    "fileName2=os.path.join(data_folder_channels,'all_channels_cat_clean.csv')\n",
    "# fileName2=os.path.join(data_folder_channels,'gta_data_clean.csv')\n",
    "df=pd.read_csv(fileName2)\n",
    "df=df.sort_values(by=['views'],ascending=True)\n",
    "df=df.fillna(\"N/A\")\n",
    "df=df.reset_index(drop=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopWords = set(stopwords.words('english'))\n",
    "searchKeys=[\"minecraft\",\"roblox\",\"call\", \"of\", \"duty\",\"overwatch\", \"grand\",\"theft\",\"auto\",\"league\",\"legend\",\n",
    "            \"Happy\",\"wheel\",\"five\", \"night\", \"at\", \"freddy's\",\"agar.io\", \"pokemon\"]\n",
    "# searchKeys=[\"grand\",\"theft\",\"auto\"]\n",
    "top_words= [\"game\", \"gaming\", \"video\", \"gameplay\", \"funny\", \"play\", \"let\",\"cod\", \"mod\", \"tutorial\"]\n",
    "# quartile3=246352\n",
    "quartile3=42267\n",
    "#punctuation list to exclude from keywords\n",
    "exclude = set(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write keywords per channel in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to delete numbers and punctuation signs\n",
    "def remove_dig_punct(list1):\n",
    "    new=[]\n",
    "    for n in range (0, len(list1)):\n",
    "        #removing digits\n",
    "        res=''.join([i for i in list1[n] if not i.isdigit()])\n",
    "        #removing punctuation\n",
    "        s = ''.join(ch for ch in res if ch not in exclude)\n",
    "        if (s !=\"\") and (s not in new):\n",
    "            if (len(s)>1):\n",
    "                new.append(s)\n",
    "    return (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries=[]\n",
    "for n in range(0,len(df)):\n",
    "    if (df.keywords[n]!=\"N/A\") and (df.views[n]>quartile3):\n",
    "        d1={}\n",
    "        channel_keys=[]\n",
    "        \n",
    "        try:\n",
    "            l = shlex.split(df.keywords[n])\n",
    "\n",
    "        except:\n",
    "            l = df.keywords[n].split()\n",
    "            \n",
    "        for kw in l:\n",
    "            kw_id = kw.lower().replace(\"'\", \"\").replace(\"´\", \"\").replace(\"’\", \"\").replace(\"`\", \"\")\n",
    "            single_keys=nltk.word_tokenize(kw_id)\n",
    "            for key in single_keys:\n",
    "                key=lemmatizer.lemmatize(key)\n",
    "                if (key not in stopWords)and(len(key)>1):\n",
    "                    if (key not in channel_keys) and (key not in searchKeys):\n",
    "                        channel_keys.append(key)\n",
    "                        \n",
    "#         clean all digits and punctuation from keywords\n",
    "        channel_keys_clean=remove_dig_punct(channel_keys)\n",
    "                    \n",
    "#         df.loc[n,\"num_tags\"]=len(channel_keys_clean)\n",
    "        for key in channel_keys_clean: d1[key]=True\n",
    "        d1[\"id\"]=df.id[n]\n",
    "        dictionaries.append(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct graph network with weighted edges (w = number of shared tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nodes with weight and title\n",
    "G=nx.Graph()\n",
    "for n in range(0,len(dictionaries)):\n",
    "    comp1=dictionaries[n]\n",
    "    channel=df.loc[df[\"id\"]==comp1[\"id\"],[\"title\", \"views\"]]\n",
    "    G.add_node(comp1[\"id\"], name=channel.title.values[0], type='channel', weight=channel.views.values[0])               \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edges with weight based on tag similarity\n",
    "for n in range(0,len(dictionaries)):\n",
    "    comp1=dictionaries[n]\n",
    "    if ((n+1)<=(len(dictionaries)-1)):\n",
    "        for m in range (n+1, len(dictionaries)):\n",
    "            comp2=dictionaries[m]\n",
    "            shared_items = len(set(comp1.items()) & set(comp2.items()))\n",
    "            if (shared_items>=5):\n",
    "                G.add_edge(comp1[\"id\"],comp2[\"id\"], weight=shared_items) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nodes(new_node, node_list, gf):\n",
    "    H =gf.copy()\n",
    "    gf.add_node(new_node, type='keyword') # Add the 'merged' node   \n",
    "\n",
    "    for n1,n2,data in H.edges(data=True):\n",
    "        # For all edges related to one of the nodes to merge,\n",
    "        # make an edge going to or coming from the `new gene`.\n",
    "        if n1 in node_list:\n",
    "            g.add_edge(new_node,n2)\n",
    "        elif n2 in node_list:\n",
    "            g.add_edge(n1,new_node)\n",
    "\n",
    "    for n in node_list: # remove the merged nodes\n",
    "        gf.remove_node(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=G.copy()\n",
    "a=list(nx.isolates(G))\n",
    "H.remove_nodes_from(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7724"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(H.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<class 'numpy.int64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7a9c8d72c758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_gexf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"similarity_tags.gexf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-568>\u001b[0m in \u001b[0;36mwrite_gexf\u001b[0;34m(G, path, encoding, prettyprint, version)\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/networkx/readwrite/gexf.py\u001b[0m in \u001b[0;36mwrite_gexf\u001b[0;34m(G, path, encoding, prettyprint, version)\u001b[0m\n\u001b[1;32m     86\u001b[0m     writer = GEXFWriter(encoding=encoding, prettyprint=prettyprint,\n\u001b[1;32m     87\u001b[0m                         version=version)\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/networkx/readwrite/gexf.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, G)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/networkx/readwrite/gexf.py\u001b[0m in \u001b[0;36madd_nodes\u001b[0;34m(self, G, graph_element)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             node_data = self.add_attributes('node', node_element,\n\u001b[0;32m--> 340\u001b[0;31m                                             node_data, default)\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mnodes_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LetsPlayData/lib/python3.5/site-packages/networkx/readwrite/gexf.py\u001b[0m in \u001b[0;36madd_attributes\u001b[0;34m(self, node_or_edge, xml_obj, data, default)\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;31m# static data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'static'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 attr_id = self.get_attr_id(make_str(k), self.xml_type[val_type],\n\u001b[0m\u001b[1;32m    437\u001b[0m                                            node_or_edge, default, mode)\n\u001b[1;32m    438\u001b[0m                 \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attvalue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'numpy.int64'>"
     ]
    }
   ],
   "source": [
    "nx.write_gexf(H,\"similarity_tags.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
